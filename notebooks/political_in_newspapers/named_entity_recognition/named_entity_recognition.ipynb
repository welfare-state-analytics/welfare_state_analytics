{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020722b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "root_folder = (lambda x: os.path.join(os.getcwd().split(x)[0], x))(\"welfare_state_analytics\")\n",
    "sys.path.append(root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf2def",
   "metadata": {},
   "source": [
    "## Convert Excel data to a yearly document index\n",
    "This script creates merges the text lines into a single text file for each year and news-paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert excel to a temporary tab seperated text file\n",
    "\n",
    "data_folder = os.path.join(root_folder, \"data\")\n",
    "source_excel_filename = os.path.join(data_folder, \"year+text_window.xlsx\")\n",
    "target_text_filename = os.path.join(data_folder, \"year+newspaper+text.txt\")\n",
    "target_zip_filename = os.path.join(data_folder, \"year+newspaper+text_yearly_document.txt.zip\")\n",
    "\n",
    "\n",
    "def create_yearly_documents(source_filename, target_name):\n",
    "\n",
    "    df: pd.DataFrame = pd.read_csv(source_filename, sep=\"\\t\")  # type: ignore\n",
    "    document_index = df.fillna(\"\").groupby([\"year\", \"newspaper\"])[\"txt\"].apply(\" \".join).reset_index()\n",
    "\n",
    "    with zipfile.ZipFile(target_name, \"w\") as zf:\n",
    "        for _, document in document_index.iterrows():\n",
    "            store_filename = \"{}_{}.txt\".format(document[\"newspaper\"], document[\"year\"])\n",
    "            zf.writestr(store_filename, document[\"txt\"], zipfile.ZIP_DEFLATED)\n",
    "\n",
    "\n",
    "if not os.path.exists(target_zip_filename):\n",
    "    print(\"Creating yearly document index...\")\n",
    "    # excel_to_csv(source_excel_filename, target_text_filename)\n",
    "    # create_yearly_documents(target_text_filename, target_zip_filename)\n",
    "\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8c4e7e",
   "metadata": {},
   "source": [
    "## Run STAGGER NER tagging\n",
    "Note that archive created above must first be unzipped into a seperate folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca06e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# nohup java -Xmx4G -jar ~/source/stagger/stagger.jar -modelfile ~/source/stagger/models/swedish.bin -lang sv -tag *.txt &\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ccd2d",
   "metadata": {},
   "source": [
    "## Compile result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfdd145",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_conll_ner_tag(filename, only_ner_tags=True):\n",
    "\n",
    "    df = pd.read_csv(filename, sep=\"\\t\", header=None, index_col=0, skip_blank_lines=True, quoting=3)  # type: ignore\n",
    "    df.columns = [\n",
    "        \"token\",\n",
    "        \"lemma\",\n",
    "        \"pos\",\n",
    "        \"F4\",\n",
    "        \"pos2\",\n",
    "        \"F6\",\n",
    "        \"F7\",\n",
    "        \"F8\",\n",
    "        \"F9\",\n",
    "        \"tag\",\n",
    "        \"type\",\n",
    "        \"id\",\n",
    "    ]\n",
    "    df = df[[\"id\", \"token\", \"pos\", \"tag\", \"type\"]]\n",
    "\n",
    "    df[\"parts\"] = df.id.str.split(\"_\")\n",
    "    df[\"paper\"] = df.parts.apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else \"??\")\n",
    "    df[\"year\"] = df.parts.apply(lambda x: x[1].split(\":\")[0] if isinstance(x, list) and len(x) > 1 else \"0\").astype(\n",
    "        np.int32\n",
    "    )\n",
    "\n",
    "    df = df[[\"paper\", \"year\", \"token\", \"tag\", \"type\"]]\n",
    "\n",
    "    if only_ner_tags:\n",
    "        df = df.loc[df.type != \"_\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "result_folder = os.path.join(data_folder, \"year+newspaper+text_yearly_document\")\n",
    "result_files = glob.glob(\"{}/*.conll\".format(result_folder))\n",
    "\n",
    "df_all_tags = pd.concat([read_conll_ner_tag(filename) for filename in result_files])\n",
    "df_all_tags.to_excel(\"year+newspaper+text_yearly_document_all_ner_tags.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e6636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
