{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f38ab29",
   "metadata": {},
   "source": [
    "# Token Count Statistics\n",
    "### Text Processing Pipeline\n",
    "\n",
    "| | Building block | Arguments | Description |\n",
    "| -- | :------------- | :------------- | :------------- |\n",
    "| ðŸ’¾ | <b>Checkpoint</b> | checkpoint_filename | Checkpoint (tagged frames) to file\n",
    "\n",
    "The PoS tagging notebook uses the same processing pipeline as the Word trends tnotebook  do to produce a tagged data frame. The processing will henceread\n",
    "a checkpoint file if it exists, otherwise resolve the full pipeline.\n",
    "\n",
    "The word count statistics are collected in the tagging task (part-of-speech and lemma annotation). The computed statistics, total word count and the word counts for each PoS-grouping, are added (or updated) to the _document index file_ as new columns. This file is stored in the tagged text archive as `document_index.csv`.\n",
    "\n",
    "Note: The dcument index file is either a pre-existing document index or, if no such index exists, automatically generated during the initial text loading pipeline task.\n",
    "If no pre-existing file exists, then the necessary attributes (e.g. document's year) are extracted from the filename of each  document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fed0e",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display\n",
    "from penelope.notebook.token_counts import tokens_count_gui\n",
    "\n",
    "import __paths__  # pylint: disable=unused-import\n",
    "\n",
    "gui = tokens_count_gui.create_token_count_gui(\n",
    "    corpus_folder=__paths__.corpus_folder,\n",
    "    resources_folder=__paths__.resources_folder,\n",
    ")\n",
    "display(gui.layout())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144729d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
