{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8864034",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Word, or part-of-word, trend analysis\n",
    "\n",
    "### Text Processing Pipeline\n",
    "\n",
    "| ðŸ”½ | Building block | Arguments | Description | Configuration\n",
    "| -- | :------------- | :------------- | :------------- | :------------- |\n",
    "| âš™ | <b>SetTagger</b>SpacyModel | 'en' | Set PoS tagger | spaCy\n",
    "| ðŸ“œ| <b>LoadText</b> | reader_opts, transform_opts | Text stream provider | config.yml\n",
    "| ðŸ”Ž | <b>Tqdm</b> | âšª | Progress indicator | âšª\n",
    "| âŒ› | <b>Passthrough</b> | âšª | Passthrough | âšª\n",
    "| ðŸ”¨ | <b>ToTaggedFrame</b> | âšª Spacy | PoS tagging | config.yml\n",
    "| ðŸ’¾ | <b>Checkpoint</b> | checkpoint_filename | Checkpoint (tagged frames) to file | âšª\n",
    "| ðŸ”¨ | TaggedFrame<b>ToTokens</b> | extract_opts | Tokens extractor | User specified\n",
    "| ðŸ”¨ | <b>TokensTransform</b> | transform_opts | Tokens transformer | User specified\n",
    "| ðŸ”Ž | <b>Tqdm</b> | âšª | Progress indicator | âšª\n",
    "| ðŸ”¨ | <b>ToDTM</b> | vectorize_opts| DTM vectorizer | User specified\n",
    "| ðŸ’¾ | <b>Checkpoint</b> | checkpoint_filename| Checkpoint (DTM) to file | User specified\n",
    "\n",
    "### User instructions\n",
    "\n",
    "#### Compute DTM\n",
    "\n",
    "This notebook implements the entire processing pipeline from plain text to a computed (and stored)\n",
    "document-term matrix (DTM) that are the basis for the word trend exploration.\n",
    "\n",
    "For large corpora the DTM processing time can be considerable and in such a case you\n",
    "should consider using the CLI-version of the processing pipeline.\n",
    "\n",
    "Note that the computed DTM is saved on disk in the specified folder. You must enter a\n",
    "tag that will be used when naming the (principal) result data file. This file will be named\n",
    "\"tag + `_vectorized_data.pickle`\" and will be used to uniquely identify the bundle of files that makes\n",
    "up the result. Note that if the `tag` already exists in the specified target folder then it will\n",
    "be overwritten. You can use the tag to describe the arguments of the computation i.e. PoS tags etc. If the `Create folder` option is checked, then the result bundle will be stored in a subfolder of the target folder named _tag_.\n",
    "\n",
    "#### Compute arguments\n",
    "\n",
    "| | Config element |  Description |\n",
    "| -- | :------------- | :------------- |\n",
    "| | Corpus type | Type of corpus, disabled since only text corpora are allowed in this notebook.\n",
    "| | Source corpus file | Select file (ZIP) or folder that contains the text documents.\n",
    "| | Output tag | String that will be prefix to result files. Only valid filename chars allowed.\n",
    "| | Output folder | Target folder for result files.\n",
    "| | Part-of-speech groups | Groups of tags to include in DTM given corpus PoS-schema\n",
    "| | Remove stopwords | Remove common stopwords using NLTK language specific stopwords\n",
    "| | Extra stopwords | Additional stopwords\n",
    "| | Filename fields | Specifies attribute values to be extracted from filenames\n",
    "\n",
    "N.B. Note that PoS schema (e.g. SUC, Universal, ON5 Penn Treebank tag sets) and language must be set for each corpus.\n",
    " This, and other options, is specified in the _corpus configuration file_. For an example, please see _SSI.yml_ inf the `resources` folder.\n",
    "\n",
    "#### Load a DTM corpus\n",
    "\n",
    "To load an existing corpus youmust first select a file, then press <b>`Load`</b>. To select the file:</b> <b>1)</b> press <b>`Change`</b> to open the file browser, <b>2)</b> find and select the file you want to open and <b>3)</b> press <b>`Change`</b> again to confirm the file and close the file browser. Then you can load the corpus by pressing <b>`Load`</b>.\n",
    "\n",
    "#### Word trends\n",
    "\n",
    "Specifiy words of interest in the text box. You can use both wildcards and regular expressions to widen your search. The\n",
    "words in the vocabulary that matches what you have specified will be listed in the selection box. Since using wildcards and regexps can result\n",
    "in a large number of words, only the `Word count` matching most frequent words are displayed. Refine your search if you get to many matches.\n",
    "The words will be plotted when they are selected. You can select and plot multiple words by pressing CTRL when selected, or using arrow keys.\n",
    "\n",
    "The regular expressions must be surrounded by vertical bars `|`. To find words ending with `tion`\n",
    "you can enter `|.*tion$|` in the textbox. I might seem cryptical, but is a very powerful notation for searching words. The vertical\n",
    "bars is specified only so that the system can distinguish the regexp from \"normal\" words. The actual expression is `^.*tion$`.\n",
    "The dot and star`.*` matches any character (the dot) any number of times (the `*`). The dollar sign `$` indicates the word ending.\n",
    "So this expression matches all words that begins with any number of characters follwoed, by the character sequence `tion` at the end of the word.\n",
    "To match all words starting with `info`you can enter `|^info.*|` where `^` specifies the start of the word.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbee576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import __paths__\n",
    "\n",
    "import penelope.notebook.word_trends.main_gui as main_gui\n",
    "from bokeh.plotting import output_notebook\n",
    "from IPython.display import display\n",
    "\n",
    "output_notebook()\n",
    "gui = main_gui.create_to_dtm_gui(\n",
    "    corpus_config=\"riksprot_1867-2019\",\n",
    "    corpus_folder=__paths__.corpus_folder,\n",
    "    data_folder=__paths__.data_folder,\n",
    "    resources_folder=\"..\",\n",
    ")\n",
    "display(gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f611f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
